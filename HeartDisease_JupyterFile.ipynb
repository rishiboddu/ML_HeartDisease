{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Can Machine Learning Algorithms Use Low-Cost Clinical Data to Effectively Predict the Onset of Heart Disease?\n",
    "</h1>\n",
    "<h2 style=\"color:Sea Green\">Siddharth Tiwari and Rishitha Boddu</h2>\n",
    "<h4>Quarter 3 Project</h4><br>\n",
    "\n",
    "<h3>Purpose</h3>\n",
    "<p>Heart Disease is one of the most costly and devastating diseases in the world, causing around 655,000 deaths per year in the United States. For this reason, it is essential for clinicians to actively screen for the risk of heart disease, especially early before its development. Although methods of screening (i.e. Blood Tests, Electrocardiography, Fluoroscopy) are available to most people, individuals may be deterred from screening due to the high cost of some screening methods. For this reason, we implement a personally-developed machine learning algorithm that uses low-cost parameters to predict the onset of heart disease. Our goal in this project is to determine if machine learning methods effectively predict the onset of heart disease with low-cost metrics.</p><br>\n",
    "\n",
    "Dataset from: <a href=\"https://www.kaggle.com/johnsmith88/heart-disease-dataset\" target=\"_blank\">https://www.kaggle.com/johnsmith88/heart-disease-dataset</a>\n",
    "<br/>\n",
    "Originally retreived from: \n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/Heart+Disease\" target=\"_blank\">https://archive.ics.uci.edu/ml/datasets/Heart+Disease</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load dataset and display\n",
    "heart_df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#E07A5F\">Describe Dataset</h2>\n",
    "\n",
    "<h4>Description from David Lapp (Publisher of the Dataset)</h4>\n",
    "<p><i>\"This dataset dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V.\"</i></p>\n",
    "\n",
    "<h4>Parameters available:</h4>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Metric Name</th>\n",
    "        <th>Metric Name (In Dataset)</th>\n",
    "        <th>Metric Summary</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Age</td>\n",
    "        <td>\"age\"</td>\n",
    "        <td>Age of patient</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Sex</td>\n",
    "        <td>\"sex\"</td>\n",
    "        <td>Sex of patient - male or female</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Chest Pain (4 Values)</td>\n",
    "        <td>\"cp\"</td>\n",
    "        <td>Chest pain type (typical angina, atypical angina, non-angina, or asymptomatic angina) represented by numbers 1-4 or 0 if inapplicable </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Resting Blood Pressure</td>\n",
    "        <td>\"restbps\"</td>\n",
    "        <td>Resting blood pressure (mm Hg). Calculated using a sphygmomanometer (consists of stethoscope, arm cuff, pump, and dial)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Serum Cholestorol (mg/dl)</td>\n",
    "        <td>\"chol\"</td>\n",
    "        <td>Serum cholesterol (mg/dl) measured in a blood test called a lipid profile/panel - show levels of high and low-density lipoprotein cholesterol and amount of triglycerides in blood</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Fasting Blood Pressure (greater than 120 mg/dl)</td>\n",
    "        <td>\"fbs\"</td>\n",
    "        <td>Blood test taken after a period of fasting (generally eight hours). Value is either greater than or less that 120 mg/dl (>120 indicates diagnosis of diabetes)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Resting Electrocardiographic (ECG) Results (3 Values)</td>\n",
    "        <td>\"restecg\"</td>\n",
    "        <td>Resting electrocardiography results (normal, ST-T wave abnormality, or left ventricular hypertrophy)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Maximum Heart Rate</td>\n",
    "        <td>\"thalach\"</td>\n",
    "        <td>Max heart rate = 220 - age</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Exercise-Induced Angina</td>\n",
    "        <td>\"exang\"</td>\n",
    "        <td>Is angina (chest pain which occurs when heart does not receive enough oxygen-rich blood) caused by exercise?</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Intercept of ST Segment (during exercise)</td>\n",
    "        <td>\"oldpeak\"</td>\n",
    "        <td>ST depression induced by exercise relative to rest. ST depression is a finding on an electrocardiogram graph</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Slope of ST Segment (during exercise)</td>\n",
    "        <td>\"slope\"</td>\n",
    "        <td>Slope of peak exercise ST segment (upsloping, flat, or downsloping)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Major Vessels Colored by Flouroscopy</td>\n",
    "        <td>\"ca\"</td>\n",
    "        <td>Number of major vessels colored by fluoroscopy, a test which uses a beam of x-rays to look at parts and movement of parts of the body</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Thalessemia</td>\n",
    "        <td>\"thal\"</td>\n",
    "        <td>Thallium stress test result (normal, fixed defect, or reversible defect) - measured through a blood test and analyzed in a lab</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Target</td>\n",
    "        <td>\"target\"</td>\n",
    "        <td>Precense or absence of heart disease in patient</td>\n",
    "    </tr>\n",
    "</table><br>\n",
    "\n",
    "<p>Although all of these metrics correlate strongly with heart disease, some require extensive amounts of money, and in this project, we look to predict these parameters using regression and classification algorithms. We call these parameters <b>Target Parameters</b> or <b>Target Params</b>. These Target Parameters are: <b>chol, fbs, restecg, exang, oldpeak, slope, ca, thal</b>. Consequently, the remaning parameters, which we call <b>Basic Parameters</b>, are: <b>age, sex, cp, restbps, thalach.</b></p><br>\n",
    "\n",
    "<p>In our machine learning method, we use the Basic Parameters to predict values for the Target Parameters. By predicting these Target Parameters, we can use both sets of parameters, Basic and Target, to predict the development of heart disease.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display dataset\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of dataset\n",
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Visualization: Seeing the Distribution of our Data </h3>\n",
    "<p> We have included a few charts to help show the distribution of data. In the pie chart, we see that 51% of our dataset is made up of patients who suffer from heart disease.</p> \n",
    "<p> We have also included a histogram to show the ages of the individuals sorted into ranges. This will help see what age group our conclusions are most relevant or accurate to. In the histogram, we see that the age range overall covers only adults as there are no kids or teens included. This may be because kids are not legally old enough to provide information for studies like this or for a more medical reason. We cannot assume anything. However, with the information we do have, it can be seen that individuals who are or are close to 60 years of age are the most common age group in our data.</p>\n",
    "<p>Finally, we have another simple pie chart that shows the split in sex. This will show how many people in the data are female vs male. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Heart Disease Present?'}, ylabel='target'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data visualization - pie chart of distribution between heart disease patients and non patients\n",
    "plt.rcParams[\"figure.figsize\"] = [8,10]\n",
    "labels = 'Heart Disease Patients', 'Non-Heart Disease Patients'\n",
    "heart_df.target.value_counts().plot(kind='pie', title = \"Heart Disease Present?\", labels = labels, autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,  39., 109., 125., 120., 205., 219., 149.,  46.,   9.]),\n",
       " array([29. , 33.8, 38.6, 43.4, 48.2, 53. , 57.8, 62.6, 67.4, 72.2, 77. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data visualization - see the distribution of ages (in ranges) of our data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "plt.title('Age Histogram')\n",
    "plt.hist(heart_df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Amount of Males vs Females in Our Data'}, ylabel='sex'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data visualization - how many females vs males do we have?\n",
    "# 1 = male, 0 = female\n",
    "plt.rcParams[\"figure.figsize\"] = [8,10]\n",
    "labels = 'Male', 'Female'\n",
    "heart_df.sex.value_counts().plot(kind='pie', title = \"Amount of Males vs Females in Our Data\", labels = labels, autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying test sets\n",
    "X = heart_df.drop(['target'], axis = 1)\n",
    "y = heart_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#08A4BD\">======================================================</h1><br><br>\n",
    "\n",
    "<h2 style=\"color:#E07A5F\">Baseline Classifications</h2>\n",
    "\n",
    "<p>We perform two classifications to compare the accuracy of classifications using all the parameters (WITH TARGET PARAMETERS) and classifications excluding the Target Parameters. By performing these classifications, we can compare the results of the baseline classification algorithms with the final classification algorithm.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Classifications\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Reports:\n",
      "[[157  32]\n",
      " [ 20 201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       189\n",
      "           1       0.86      0.91      0.89       221\n",
      "\n",
      "    accuracy                           0.87       410\n",
      "   macro avg       0.87      0.87      0.87       410\n",
      "weighted avg       0.87      0.87      0.87       410\n",
      "\n",
      "0.8731707317073171\n",
      "\n",
      "\n",
      "SVM Reports:\n",
      "[[181   8]\n",
      " [ 17 204]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       189\n",
      "           1       0.96      0.92      0.94       221\n",
      "\n",
      "    accuracy                           0.94       410\n",
      "   macro avg       0.94      0.94      0.94       410\n",
      "weighted avg       0.94      0.94      0.94       410\n",
      "\n",
      "0.9390243902439024\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[158  31]\n",
      " [ 30 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       189\n",
      "           1       0.86      0.86      0.86       221\n",
      "\n",
      "    accuracy                           0.85       410\n",
      "   macro avg       0.85      0.85      0.85       410\n",
      "weighted avg       0.85      0.85      0.85       410\n",
      "\n",
      "0.8512195121951219\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression()\n",
    "classifier = log_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental Classifications\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Reports:\n",
      "[[154  35]\n",
      " [ 47 174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       189\n",
      "           1       0.83      0.79      0.81       221\n",
      "\n",
      "    accuracy                           0.80       410\n",
      "   macro avg       0.80      0.80      0.80       410\n",
      "weighted avg       0.80      0.80      0.80       410\n",
      "\n",
      "0.8\n",
      "\n",
      "\n",
      "SVM Reports:\n",
      "[[164  25]\n",
      " [ 52 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       189\n",
      "           1       0.87      0.76      0.81       221\n",
      "\n",
      "    accuracy                           0.81       410\n",
      "   macro avg       0.82      0.82      0.81       410\n",
      "weighted avg       0.82      0.81      0.81       410\n",
      "\n",
      "0.8121951219512196\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[162  27]\n",
      " [ 47 174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.81       189\n",
      "           1       0.87      0.79      0.82       221\n",
      "\n",
      "    accuracy                           0.82       410\n",
      "   macro avg       0.82      0.82      0.82       410\n",
      "weighted avg       0.82      0.82      0.82       410\n",
      "\n",
      "0.8195121951219512\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression()\n",
    "classifier = log_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Sea Green\">Baseline Classification Results</h3>\n",
    "<h4>Accuracy scores for baseline classifications.</h4>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Classifier</th>\n",
    "        <th>Accuracy Score (With Target Params)</th>\n",
    "        <th>Accuracy Score (Without Target Params)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Logistic Regression</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.80</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>SVM</td>\n",
    "        <td>0.939</td>\n",
    "        <td>0.812</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><i>k-</i>NearestNeighbors</td>\n",
    "        <td>0.851</td>\n",
    "        <td>0.819</td>\n",
    "    </tr>\n",
    "</table><br>\n",
    "\n",
    "<p>A stark difference emerges between the two algorithms by including or excluding the Target Params. We use the classifications that exclude Target Params as the baseline for our final classification algorithm.</p>\n",
    "\n",
    "<h1 style=\"color:#08A4BD\">======================================================</h1><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#E07A5F\">Regressions/Classifications of Parameters</h2>\n",
    "\n",
    "<p>Here, we perform different classifications or regressions depending on the type of parameter. The algorithms with the highest accuracy will be implemented in the final algorithm.</p>\n",
    "\n",
    "<h4>Target Parameter Classifications/Regressions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "Root Mean Squared 49.07917733926613\n",
      "\n",
      "\n",
      "Random Forest Reports:\n",
      "Root Mean Squared 49.07917733926613\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "Root Mean Squared 37.69630933930904\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#chol\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['chol']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "svm_reg = svm.SVR()\n",
    "regressor = svm_reg.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"SVM Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state=42, n_estimators=500)\n",
    "regressor = rf_reg.fit(X_train, y_train)\n",
    "print(\"Random Forest Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=4)\n",
    "regressor = knn_reg.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"KNN Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "[[346   0]\n",
      " [ 64   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       346\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.84       410\n",
      "   macro avg       0.42      0.50      0.46       410\n",
      "weighted avg       0.71      0.84      0.77       410\n",
      "\n",
      "0.8439024390243902\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reports:\n",
      "[[346   0]\n",
      " [  6  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       346\n",
      "           1       1.00      0.91      0.95        64\n",
      "\n",
      "    accuracy                           0.99       410\n",
      "   macro avg       0.99      0.95      0.97       410\n",
      "weighted avg       0.99      0.99      0.99       410\n",
      "\n",
      "0.9853658536585366\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[342   4]\n",
      " [ 59   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       346\n",
      "           1       0.56      0.08      0.14        64\n",
      "\n",
      "    accuracy                           0.85       410\n",
      "   macro avg       0.70      0.53      0.53       410\n",
      "weighted avg       0.81      0.85      0.79       410\n",
      "\n",
      "0.8463414634146341\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fbs\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['fbs']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using RandomForest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "classifier = rf_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"Random Forest Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 10)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "[[121  58   0]\n",
      " [100 126   0]\n",
      " [  3   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60       179\n",
      "           1       0.68      0.56      0.61       226\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.60       410\n",
      "   macro avg       0.41      0.41      0.40       410\n",
      "weighted avg       0.61      0.60      0.60       410\n",
      "\n",
      "0.6024390243902439\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reports:\n",
      "[[170   9   0]\n",
      " [ 13 213   0]\n",
      " [  0   0   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       179\n",
      "           1       0.96      0.94      0.95       226\n",
      "           2       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.95       410\n",
      "   macro avg       0.96      0.96      0.96       410\n",
      "weighted avg       0.95      0.95      0.95       410\n",
      "\n",
      "0.9463414634146341\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[133  45   1]\n",
      " [100 126   0]\n",
      " [  3   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.74      0.64       179\n",
      "           1       0.73      0.56      0.63       226\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.63       410\n",
      "   macro avg       0.43      0.43      0.42       410\n",
      "weighted avg       0.65      0.63      0.63       410\n",
      "\n",
      "0.6317073170731707\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#restecg\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['restecg']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using RandomForest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "classifier = rf_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"Random Forest Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 10)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "[[242  24]\n",
      " [ 51  93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       266\n",
      "           1       0.79      0.65      0.71       144\n",
      "\n",
      "    accuracy                           0.82       410\n",
      "   macro avg       0.81      0.78      0.79       410\n",
      "weighted avg       0.82      0.82      0.81       410\n",
      "\n",
      "0.8170731707317073\n",
      "\n",
      "\n",
      "Random Forest Reports:\n",
      "[[266   0]\n",
      " [ 12 132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       266\n",
      "           1       1.00      0.92      0.96       144\n",
      "\n",
      "    accuracy                           0.97       410\n",
      "   macro avg       0.98      0.96      0.97       410\n",
      "weighted avg       0.97      0.97      0.97       410\n",
      "\n",
      "0.9707317073170731\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[228  38]\n",
      " [ 60  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       266\n",
      "           1       0.69      0.58      0.63       144\n",
      "\n",
      "    accuracy                           0.76       410\n",
      "   macro avg       0.74      0.72      0.73       410\n",
      "weighted avg       0.76      0.76      0.76       410\n",
      "\n",
      "0.7609756097560976\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exang\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['exang']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using RandomForest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "classifier = rf_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"Random Forest Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 10)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "Root Mean Squared 1.0372559662717435\n",
      "\n",
      "\n",
      "Random Forest Reports:\n",
      "Root Mean Squared 1.0372559662717435\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "Root Mean Squared 0.9204817137596236\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#oldpeak\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['oldpeak']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn import svm\n",
    "svm_reg = svm.SVR()\n",
    "regressor = svm_reg.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"SVM Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state=42, n_estimators=500)\n",
    "regressor = rf_reg.fit(X_train, y_train)\n",
    "print(\"Random Forest Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=6)\n",
    "regressor = knn_reg.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"KNN Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "Root Mean Squared 0.5502044346512335\n",
      "\n",
      "\n",
      "Random Forest Reports:\n",
      "Root Mean Squared 0.5502044346512335\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "Root Mean Squared 0.5097291910794225\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slope\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['slope']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn import svm\n",
    "svm_reg = svm.SVR()\n",
    "regressor = svm_reg.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"SVM Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state=42, n_estimators=500)\n",
    "regressor = rf_reg.fit(X_train, y_train)\n",
    "print(\"Random Forest Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=6)\n",
    "regressor = knn_reg.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"KNN Reports:\")\n",
    "print('Root Mean Squared', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "[[219   7   8   0   0]\n",
      " [ 57  36   3   0   0]\n",
      " [ 25  13   8   0   0]\n",
      " [ 13   8   4   3   0]\n",
      " [  6   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79       234\n",
      "           1       0.56      0.38      0.45        96\n",
      "           2       0.35      0.17      0.23        46\n",
      "           3       1.00      0.11      0.19        28\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.65       410\n",
      "   macro avg       0.52      0.32      0.33       410\n",
      "weighted avg       0.63      0.65      0.60       410\n",
      "\n",
      "0.6487804878048781\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reports:\n",
      "[[224   7   0   3   0]\n",
      " [  6  90   0   0   0]\n",
      " [  0   0  46   0   0]\n",
      " [  0   0   0  28   0]\n",
      " [  0   0   0   0   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       234\n",
      "           1       0.93      0.94      0.93        96\n",
      "           2       1.00      1.00      1.00        46\n",
      "           3       0.90      1.00      0.95        28\n",
      "           4       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.96       410\n",
      "   macro avg       0.96      0.98      0.97       410\n",
      "weighted avg       0.96      0.96      0.96       410\n",
      "\n",
      "0.9609756097560975\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[209  16   7   1   1]\n",
      " [ 48  40   7   1   0]\n",
      " [ 23   7  16   0   0]\n",
      " [ 11   6   6   5   0]\n",
      " [  6   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.79       234\n",
      "           1       0.58      0.42      0.48        96\n",
      "           2       0.44      0.35      0.39        46\n",
      "           3       0.71      0.18      0.29        28\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.66       410\n",
      "   macro avg       0.49      0.37      0.39       410\n",
      "weighted avg       0.64      0.66      0.63       410\n",
      "\n",
      "0.6585365853658537\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ca\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['ca']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#using RandomForest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "classifier = rf_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"Random Forest Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 10)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reports:\n",
      "[[  0   0   1   2]\n",
      " [  0   1   5  19]\n",
      " [  0   0 184  35]\n",
      " [  0   0  32 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       1.00      0.04      0.08        25\n",
      "           2       0.83      0.84      0.83       219\n",
      "           3       0.70      0.80      0.75       163\n",
      "\n",
      "    accuracy                           0.77       410\n",
      "   macro avg       0.63      0.42      0.41       410\n",
      "weighted avg       0.78      0.77      0.75       410\n",
      "\n",
      "0.7707317073170732\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reports:\n",
      "[[  3   0   0   0]\n",
      " [  0  22   3   0]\n",
      " [  0   0 213   6]\n",
      " [  0   0   3 160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      0.88      0.94        25\n",
      "           2       0.97      0.97      0.97       219\n",
      "           3       0.96      0.98      0.97       163\n",
      "\n",
      "    accuracy                           0.97       410\n",
      "   macro avg       0.98      0.96      0.97       410\n",
      "weighted avg       0.97      0.97      0.97       410\n",
      "\n",
      "0.9707317073170731\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[  0   0   1   2]\n",
      " [  0   6   7  12]\n",
      " [  0   2 183  34]\n",
      " [  0   1  43 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.67      0.24      0.35        25\n",
      "           2       0.78      0.84      0.81       219\n",
      "           3       0.71      0.73      0.72       163\n",
      "\n",
      "    accuracy                           0.75       410\n",
      "   macro avg       0.54      0.45      0.47       410\n",
      "weighted avg       0.74      0.75      0.74       410\n",
      "\n",
      "0.751219512195122\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#thal\n",
    "\n",
    "#specifying test sets\n",
    "X_1 = X.drop(['chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df['thal']\n",
    "\n",
    "#setting train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using RandomForest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "classifier = rf_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"Random Forest Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 10)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Sea Green\">Target Paramater Regression/Classification Results</h3>\n",
    "<h4>Root Mean Square Errors for Target Parameter Regressions.</h4>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Target Parameter</th>\n",
    "        <th>SVM Regression</th>\n",
    "        <th>Random Forest Regression</th>\n",
    "        <th>KNN Regression</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>chol</td>\n",
    "        <td>49.08</td>\n",
    "        <td>49.08</td>\n",
    "        <td>37.70</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>oldpeak</td>\n",
    "        <td>1.04</td>\n",
    "        <td>1.04</td>\n",
    "        <td>0.95</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>slope</td>\n",
    "        <td>0.55</td>\n",
    "        <td>0.55</td>\n",
    "        <td>0.51</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h4>Accuracy scores for Target Parameter Classifications.</h4>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Target Parameter</th>\n",
    "        <th>SVM Classification</th>\n",
    "        <th>Random Forest Classification</th>\n",
    "        <th>KNN Classification</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>fbs</td>\n",
    "        <td>0.844</td>\n",
    "        <td>0.985</td>\n",
    "        <td>0.846</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>restecg</td>\n",
    "        <td>0.602</td>\n",
    "        <td>0.946</td>\n",
    "        <td>0.631</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>exang</td>\n",
    "        <td>0.817</td>\n",
    "        <td>0.971</td>\n",
    "        <td>0.760</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>ca</td>\n",
    "        <td>0.649</td>\n",
    "        <td>0.961</td>\n",
    "        <td>0.659</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>thal</td>\n",
    "        <td>0.771</td>\n",
    "        <td>0.971</td>\n",
    "        <td>0.751</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h1 style=\"color:#08A4BD\">======================================================</h1><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#E07A5F\">Final Classifications</h2>\n",
    "\n",
    "<p>We use the predictions the previous regressions/classifications for the target parameters (chol, fbs, restecg, exang, oldpeak, slope, ca, thal) in a final classification algorithm. In this final classification algorithm, we use the algorithms with the highest accuracy (lowest root mean square error for regressions/highest accuracy score for classifications).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Reports:\n",
      "[[155  34]\n",
      " [ 26 195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       189\n",
      "           1       0.85      0.88      0.87       221\n",
      "\n",
      "    accuracy                           0.85       410\n",
      "   macro avg       0.85      0.85      0.85       410\n",
      "weighted avg       0.85      0.85      0.85       410\n",
      "\n",
      "0.8536585365853658\n",
      "\n",
      "\n",
      "SVM Reports:\n",
      "[[176  13]\n",
      " [ 28 193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       189\n",
      "           1       0.94      0.87      0.90       221\n",
      "\n",
      "    accuracy                           0.90       410\n",
      "   macro avg       0.90      0.90      0.90       410\n",
      "weighted avg       0.90      0.90      0.90       410\n",
      "\n",
      "0.9\n",
      "\n",
      "\n",
      "KNN Reports:\n",
      "[[161  28]\n",
      " [ 34 187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       189\n",
      "           1       0.87      0.85      0.86       221\n",
      "\n",
      "    accuracy                           0.85       410\n",
      "   macro avg       0.85      0.85      0.85       410\n",
      "weighted avg       0.85      0.85      0.85       410\n",
      "\n",
      "0.848780487804878\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#list with all target params\n",
    "target_params = ['chol', 'oldpeak','slope', 'fbs','restecg','exang','ca','thal']\n",
    "\n",
    "#dictionary to store predictions for target params\n",
    "predictors = {\"chol\":[],\n",
    "             \"oldpeak\":[],\n",
    "             \"slope\":[],\n",
    "             \"fbs\":[],\n",
    "             \"restecg\":[],\n",
    "             \"exang\":[],\n",
    "             \"ca\":[],\n",
    "             \"thal\":[]}\n",
    "\n",
    "#specifying sets\n",
    "X_1 = heart_df.drop(['target','chol', 'restecg', 'exang', 'thal','oldpeak','slope','fbs','ca'], axis = 1)\n",
    "y = heart_df[target_params + ['target']]\n",
    "\n",
    "#dividing into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_all = sc.transform(X_1)\n",
    "\n",
    "#run regressions/classifications and store into dictionary\n",
    "for i in range(len(target_params)):\n",
    "    if(i<3):\n",
    "        knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "        regressor = knn_reg.fit(X_train,y_train[target_params[i]])\n",
    "        predictors[target_params[i]] = regressor.predict(X_all)\n",
    "        \n",
    "    else:\n",
    "        rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "        classifier = rf_clf.fit(X_train, y_train[target_params[i]])\n",
    "        predictors[target_params[i]] = classifier.predict(X_all)\n",
    "    \n",
    "\n",
    "# convert dictionary to dataframe\n",
    "X_2 = pd.DataFrame.from_dict(predictors)\n",
    "\n",
    "\n",
    "#FINAL CLASSIFICATION METHOD (Using basic parameters and target parameters to determine 'target')\n",
    "\n",
    "#specifying sets\n",
    "X = pd.concat([X_1, X_2], axis=1)\n",
    "y = heart_df['target']\n",
    "\n",
    "#dividing data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)\n",
    "\n",
    "#scaling data\n",
    "sc = StandardScaler()\n",
    "#scaling the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "#scaling the test set\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "#using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression()\n",
    "classifier = log_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#using SVM algorithm\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "classifier = svm_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"SVM Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#using KNN Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier = knn_clf.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#printing reports\n",
    "print(\"KNN Reports:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Sea Green\">Final Classification Results</h3>\n",
    "<h4>Accuracy scores for all classifications.</h4>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Classifier</th>\n",
    "        <th>Accuracy Score (Including Target Params)</th>\n",
    "        <th>Accuracy Score (Excluding Target Params)</th>\n",
    "        <th>Accuracy Score (Including <i>Predicted</i> Target Params)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Logistic Regression</td>\n",
    "        <td>0.873</td>\n",
    "        <td>0.80</td>\n",
    "        <td>0.854</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>SVM</td>\n",
    "        <td>0.939</td>\n",
    "        <td>0.812</td>\n",
    "        <td>0.9</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><i>k-</i>NearestNeighbors</td>\n",
    "        <td>0.851</td>\n",
    "        <td>0.819</td>\n",
    "        <td>0.849</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h1 style=\"color:#08A4BD\">======================================================</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusion</h1>\n",
    "\n",
    "<p>By classifying or regression high-cost screening results (target parameters) using low-cost, readily available metrics (basic parameters), we can increase the accuracy of predictions substantially. Although other algorithms may be better suited for these data (classify the data more accurately/practically), our use of a simple combination of regressions and classification algorithms show that it is possible to use five metrics to predict results with relative accuracy. Hopefully, through further exploration of these data and implementation of more complex, extensive algorithms, clinicans can use simple clinical data to screen for the possibility of heart disease.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
